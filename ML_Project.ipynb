{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNUVYRFeqGlFleOqGu7wAxq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shaik1903/Vision-Transformer-from-scratch-ML-Project-/blob/main/ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZRUwhJyTIsNM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCBQrnLfg7Ve",
        "outputId": "6eb06abd-d3cc-497f-ddd0-83e4259a3bbe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/MyDrive/ML Project/mini/small\"\n",
        "output_path = \"/content/drive/MyDrive/ML Project/mini/output\""
      ],
      "metadata": {
        "id": "OPDTdZRdhES1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resizing the images and transfroming them into tensors\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "kXulu6S_h_6U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "dataset = ImageFolder(root=data_path, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "-xtQ_EaNiFMF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desired_dim = 512  # Adjust the desired dimension according to your requirements\n",
        "linear_projection = torch.nn.Linear(256 * 256, desired_dim)"
      ],
      "metadata": {
        "id": "JBOonC1TiWgi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to store the projected patches\n",
        "all_projected_patches = []"
      ],
      "metadata": {
        "id": "8cIYT_TAobTv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for phase in [\"train\", \"test\", \"val\"]:\n",
        "    phase_path = os.path.join(data_path, phase)\n",
        "    for label in os.listdir(phase_path):\n",
        "        label_path = os.path.join(phase_path, label)\n",
        "        for root, _, files in os.walk(label_path):\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    image_path = os.path.join(root, file)\n",
        "                    image = Image.open(image_path)\n",
        "                    image = transform(image)\n",
        "                    b, h, w = image.size()\n",
        "                    flattened_patches = image.view(b, -1)\n",
        "                    projected_patches = linear_projection(flattened_patches)\n",
        "                    # Add the projected patches to the list\n",
        "                    all_projected_patches.append(projected_patches)\n",
        "# Convert the list to a torch tensor\n",
        "all_projected_patches = torch.stack(all_projected_patches)\n",
        "\n",
        "# Save the projected patches as a .pt file\n",
        "output_file_path = os.path.join(output_path, \"projected_patches.pt\")\n",
        "torch.save(all_projected_patches, output_file_path)\n",
        "\n",
        "print(f\"Projected patches saved at {output_file_path}\")"
      ],
      "metadata": {
        "id": "5w15UFeNmGuk",
        "outputId": "4c560d36-b6bc-4030-ed37-56e78d3637f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Projected patches saved at /content/drive/MyDrive/ML Project/mini/output/projected_patches.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_file_path = \"/content/drive/MyDrive/ML Project/mini/output/projected_patches.pt\""
      ],
      "metadata": {
        "id": "XvqVEq8nmeOp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the projected patches\n",
        "loaded_data = torch.load(saved_file_path)"
      ],
      "metadata": {
        "id": "ZNNK-f86n6t5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of the loaded data\n",
        "print(\"Loaded data shape:\", loaded_data.shape)"
      ],
      "metadata": {
        "id": "V0yV4Q4cpdY1",
        "outputId": "e1d245af-eb1a-4524-c327-5ef4310b9bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded data shape: torch.Size([3002, 1, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HFUic20ppgs4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}